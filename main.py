from pathlib import Path
import time

import config
from query_generator import PythonAssistant

# M√°ximo de caracteres del contexto del profesor para no hacer el prompt gigante
MAX_CONTEXT_CHARS = 8000  # si sigue lento, baj√° a 4000 o 2000


def load_teacher_context(path: str) -> str:
    """
    Lee el archivo .md con los c√≥digos/apuntes del profesor y lo recorta
    a un m√°ximo de caracteres para que el prompt no se vuelva enorme.
    """
    p = Path(path)
    if not p.exists():
        return ""
    try:
        txt = p.read_text(encoding="utf-8").strip()
    except Exception:
        return ""

    if len(txt) > MAX_CONTEXT_CHARS:
        # Nos quedamos con el final, que suele tener lo m√°s reciente/relevante
        txt = txt[-MAX_CONTEXT_CHARS:]

    return txt


def is_theory_question(text: str) -> bool:
    """
    Heur√≠stica sencilla para detectar si la pregunta es te√≥rica.
    Si es teor√≠a ‚Üí el modelo puede explicar.
    Si no ‚Üí solo c√≥digo.
    """
    t = text.lower()

    theory_keywords = [
        "explica",
        "expl√≠came",
        "explicame",
        "qu√© es",
        "que es",
        "defin√≠",
        "definime",
        "teor√≠a",
        "concepto",
        "diferencia entre",
        "para que sirve",
        "para qu√© sirve",
        "como funciona",
        "c√≥mo funciona",
        "qu√© hace este c√≥digo",
        "que hace este codigo",
    ]

    return any(kw in t for kw in theory_keywords)


def build_prompt(teacher_context: str, question: str, mode: str) -> str:
    """
    Construye el prompt que se env√≠a al modelo.
    """
    parts: list[str] = []

    if teacher_context:
        parts.append(
            "Estos son apuntes y c√≥digos de referencia del profesor, en formato Markdown.\n"
            "√ösalos solo como gu√≠a de estilo y nivel de dificultad. No copies todo literal.\n\n"
            "=== APUNTES DEL PROFESOR (INICIO) ===\n"
        )
        parts.append(teacher_context)
        parts.append("\n=== APUNTES DEL PROFESOR (FIN) ===\n\n")

    parts.append(
        "Contexto del alumno: est√° preparando un EXAMEN de programaci√≥n en Python.\n"
        "Sigue el estilo de los ejemplos del profesor: c√≥digo claro, directo y sencillo.\n\n"
    )

    if mode == "code":
        parts.append(
            "La siguiente petici√≥n del alumno requiere SOLO C√ìDIGO PYTHON.\n"
            "No debes escribir explicaciones ni texto adicional, solo el c√≥digo final.\n\n"
        )
    else:
        parts.append(
            "La siguiente petici√≥n del alumno es de TEOR√çA o explicaci√≥n.\n"
            "Puedes explicar brevemente en espa√±ol neutro y, si ayuda, agregar ejemplos de c√≥digo.\n\n"
        )

    parts.append("Pregunta / pedido del alumno:\n")
    parts.append(question.strip())

    return "".join(parts)


def main() -> None:
    print("=== Asistente de PYTHON para examen ===\n")
    print("Este asistente usa los c√≥digos del profesor como referencia.\n")
    print("Modo de respuesta:")
    print("  - Pregunta normal (ej: 'haceme una funci√≥n que...') ‚Üí SOLO c√≥digo Python.")
    print("  - Pregunta te√≥rica (ej: 'explicame qu√© es un while') ‚Üí explicaci√≥n breve.\n")
    print("Comandos especiales:")
    print("  '!rapido ...' ‚Üí NO usa el contexto del profesor (m√°s r√°pido).")
    print("  'salir'       ‚Üí terminar el programa.\n")

    teacher_context = load_teacher_context(config.TEACHER_CONTEXT_PATH)
    if teacher_context:
        print(f"Contexto del profesor cargado desde: {config.TEACHER_CONTEXT_PATH}\n")
    else:
        print(
            f"ADVERTENCIA: No se encontr√≥ '{config.TEACHER_CONTEXT_PATH}' "
            "o est√° vac√≠o. El asistente funcionar√° sin ejemplos del profesor.\n"
        )

    assistant = PythonAssistant(
        host=config.OLLAMA_HOST,
        model=config.OLLAMA_MODEL,
        options=config.OLLAMA_OPTIONS,
    )

    while True:
        question = input("T√∫: ").strip()
        if not question:
            continue

        if question.lower() in ("salir", "exit", "quit"):
            print("¬°√âxitos en el examen! üëã")
            break

        # Modo r√°pido: no incluimos el contexto del profesor
        use_context = True
        if question.startswith("!rapido "):
            use_context = False
            question = question[len("!rapido "):].strip()

        mode = "theory" if is_theory_question(question) else "code"
        current_context = teacher_context if use_context else ""

        full_prompt = build_prompt(current_context, question, mode)

        start = time.time()
        response = assistant.generate_response(full_prompt, mode=mode)
        elapsed = time.time() - start

        print("\n--- Respuesta ---\n")
        print(response)
        print(f"\n--- Tiempo de respuesta: {elapsed:.2f} segundos ---\n")


if __name__ == "__main__":
    main()
